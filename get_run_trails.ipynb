{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy, glob, geohash2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_of_gpx_file(val_filename):\n",
    "    df_rtn_val = []\n",
    "    try:\n",
    "        gpx_file = open(val_filename, 'r')\n",
    "        gpx = gpxpy.parse(gpx_file)\n",
    "        for i in range(len(gpx.tracks)):\n",
    "            for j in range(len(gpx.tracks[i].segments)):\n",
    "                data = gpx.tracks[i].segments[j].points\n",
    "                df = pd.DataFrame(columns=['Lon', 'Lat', 'Alt', 'Time'])\n",
    "                for point in data:\n",
    "                    df = df.append({'Lon': point.longitude, 'Lat': point.latitude, 'Alt': point.elevation, 'Time': str(point.time)},ignore_index=True)\n",
    "                df['Track'] = i\n",
    "                df['Segment'] = j\n",
    "                df['Src'] = val_filename\n",
    "                df_rtn_val.append(df)\n",
    "        df_rtn_val = pd.concat(df_rtn_val)\n",
    "    except:\n",
    "        print('ERROR: Could not process file named = '+val_filename)\n",
    "    return(df_rtn_val)\n",
    "\n",
    "def get_hashes(df_src,val_precision=8,col_lat='Lat',col_lon='Lon'):\n",
    "    df_src['Geohash'] = df_src.apply(lambda x: geohash2.encode(x[col_lat],x[col_lon],precision=val_precision),axis=1)\n",
    "    return(df_src)\n",
    "\n",
    "def get_df_unique_hashes(df_src,col_identifier='Src',col_geohash='Geohash'):\n",
    "    vec_unique_runs = df_src[col_identifier].unique()\n",
    "    df_geohashes = pd.DataFrame(columns=[col_identifier,'Unique'+col_geohash])\n",
    "    for i in vec_unique_runs:\n",
    "        df_tmp = df_src[df_src[col_identifier]==i].copy()\n",
    "        tmp_unique_geohashes = df_tmp[col_geohash].unique()\n",
    "        df_geohashes = df_geohashes.append({col_identifier:i,'Unique'+col_geohash:tmp_unique_geohashes},ignore_index=True)\n",
    "    return(df_geohashes)\n",
    "\n",
    "def compare_geohashes(str_src_file,df_src,col_identifier='Src',col_unique_geohash='UniqueGeohash'):\n",
    "    df_geohashes_src = df_src.loc[df_src[col_identifier]==str_src_file].copy()\n",
    "    df_geohashes_others = df_src.loc[~(df_src[col_identifier]==str_src_file)].copy()\n",
    "    set_src_geohashes = []\n",
    "    for i,row in df_geohashes_src.iterrows():\n",
    "        tmp_geohashes = row[col_unique_geohash].tolist()\n",
    "        set_src_geohashes.extend(tmp_geohashes)\n",
    "    set_other_geohashes = []\n",
    "    for i,row in df_geohashes_others.iterrows():\n",
    "        tmp_geohashes = row[col_unique_geohash].tolist()\n",
    "        set_other_geohashes.extend(tmp_geohashes)\n",
    "    print('Source Geohashes = '+str(len(set_src_geohashes)))\n",
    "    print('Sink Geohashes = '+str(len(set_other_geohashes)))\n",
    "    rtn_val = set(set_src_geohashes)-set(set_other_geohashes)\n",
    "    return(rtn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2584, 8)\n",
      "CPU times: user 4.15 s, sys: 36.2 ms, total: 4.18 s\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_files = glob.glob('./Data/*.gpx')\n",
    "df_gpx_rtn_val = []\n",
    "for i in val_files:\n",
    "    df_gpx_rtn_val.append(get_df_of_gpx_file(i))\n",
    "df_gpx = pd.concat(df_gpx_rtn_val)\n",
    "df_runner = get_hashes(df_gpx)\n",
    "df_geohashes = get_df_unique_hashes(df_runner)\n",
    "print(df_runner.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Geohashes = 0\n",
      "Sink Geohashes = 461\n",
      "CPU times: user 2.35 ms, sys: 156 Âµs, total: 2.5 ms\n",
      "Wall time: 2.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unique_hashes = compare_geohashes(str_src_file='./2019-03-16_Run.gpx',df_src=df_geohashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_runner[df_runner['Geohash'].isin(list(unique_hashes))].copy().to_excel('./Data/Output.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Env_Scratch]",
   "language": "python",
   "name": "conda-env-Env_Scratch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
